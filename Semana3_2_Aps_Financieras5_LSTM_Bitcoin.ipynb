{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RYU-MCFLY/Algebra_lineal-para-ML/blob/main/Semana3_2_Aps_Financieras5_LSTM_Bitcoin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MaxMitre/Aplicaciones-Financieras/blob/main/Semana3/2_LSTM_Bitcoin.ipynb)\n",
        "\n"
      ],
      "metadata": {
        "id": "bkUeov5T9Hfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descripción del problema"
      ],
      "metadata": {
        "id": "6DuKgmeStDUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datos originales: https://challengedata.ens.fr/participants/challenges/31/\n",
        "\n",
        "El problema trata de buscar un algoritmo de clasificación que ayude a crear estrategias de inversión en criptomonedas, basado en el \"sentimiento\" extraído de noticias y redes sociales.\n",
        "\n",
        "Por cada hora de trading se contabilizó la ocurrencia de algunos terminos, tales como 'adoption' y 'hack', en un selecto numero de cuentas influyentes de twitter y en algunos foros como 'Bitcointalk'.\n",
        "\n",
        "Se han creado 10 temas diferentes, algunos positivos y otros negativos y se han contabilizado las palabras antes mencionadas, antes de una normalización.\n",
        "\n",
        "Dado un tema y un tema, hemos visto los conteos de las últimas 48 horas y se estandarizaron esos conteos. El resultado se multiplicó por el conteo promedio por hora y se dividió por el conteo promedio por hora de todo el entrenamiento\n",
        "\n",
        "Para un tiempo T en el periodo de tiempo i, con lag k ($k\\in[\\![0;47]\\!]$) el valor F ode la característica será:\n",
        "\n",
        "$$\n",
        "F_{i,k}=\\frac{T_{i,k}-\\overline{T_{i}}}{\\sqrt{\\frac{1}{47}\\sum\\limits_{j=0}^{47}{(T_{i,j}-\\overline{T_{i}})^{2}}}}*\\frac{\\overline{T_i}}{\\overline{T}} \n",
        "$$\n",
        "\n",
        "\n",
        "Se agregaron 5 características correspondientes a los precios finales en periodos de 1 hr, 6 hrs, 12 hrs, 24 hrs y 48 hrs\n",
        "El objetivo es predecir si el precio del Bitcoin tendrá un retorno (en la próxima hora) que sea de mas del 0.2%, entre -0.2% y 0.2% o menos al -0.2%.\n",
        "\n",
        "La métrica utilizada para la perdida es la perdida logistica, definita como el negativo de la log-verosimilitud de las etiquetas verdaderas comparadas con las probabilidades predichas por el clasificador.\n",
        "\n",
        "Las verdaderas etiquetas están codificadas como una matríz de 3 columnas, donde hay unos o ceros dependiendo si el elemento pertenece a la categoría de una columna u otra.\n",
        " \n",
        "Dada una matriz P de probabilidades $p_{i,k}=Pr(t_{i,k}=1)'$ , la función de perdida se define como\n",
        "\n",
        "$$\n",
        "L_{log}(Y,P)=-log{Pr(Y|P)}=-\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{k=1}^3{y_{i,k}log(p_{i,k})}\n",
        "$$\n",
        "\n",
        "Entre más bajo el score de ésta medida, mejor.\n",
        "\n"
      ],
      "metadata": {
        "id": "E454T2Z7s_Tb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencias"
      ],
      "metadata": {
        "id": "I1za57pz8Mkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U plotly"
      ],
      "metadata": {
        "id": "tIthEMHkPBww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9Ifan8XrfuZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HV21Dtfz0SF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funciones"
      ],
      "metadata": {
        "id": "sqFcegOL8N7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(estimator, train, val, test):\n",
        "    print('train cross_entropy = ', estimator.evaluate(train[0], train[1], verbose = False))\n",
        "    print('  val cross_entropy = ', estimator.evaluate(val[0], val[1], verbose = False))\n",
        "    print(' test cross_entropy = ', estimator.evaluate(test[0], test[1], verbose = False))"
      ],
      "metadata": {
        "id": "Mv_00PdK2Wnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Modificar para seleccionar características cambiando n_features, no sólo las primeras n_features\n",
        "# TODO: Revisar los resultados generados cuando se seleccionan distintos parámetros\n",
        "# NOTE: Asuma que el dataframe tiene 5 X, y 48 columnas para cada una de las 10 I ordenadas de reciente a antigua\n",
        "def transform_dataframe(df, len_prices = 5, n_features = 10, len_features = 48):\n",
        "    if type(len_prices) != int or type(n_features) != int or type(len_features) != int:\n",
        "        raise ValueError(f'Los parámetros len_prices, n_features y len_features deben ser de tipo int. Recibibo {type(len_prices)},{type(n_features)} y {type(len_features)}')\n",
        "\n",
        "    assert 0 < len_prices <= 5, 'len_prices debe estar entre 1 y 5'\n",
        "    assert 0 < n_features <= 10, 'n_features debe estar entre 1 y 10'\n",
        "    assert 0 < len_features <= 48, 'len_features debe estar entre 1 y 48'\n",
        "\n",
        "    df.reset_index(inplace = True, drop = True)\n",
        "    \n",
        "    # Los nombres de las columnas están al reves para tener primer la observación más antigua\n",
        "    prices_cols = ['X5', 'X4', 'X3', 'X2', 'X1']\n",
        "\n",
        "    prices = np.zeros((len(df), len_prices, 1))\n",
        "    features = np.zeros((len(df), len_features, n_features))\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        # Se transforman la forma de los precios\n",
        "        prices[i] = df.loc[i, prices_cols[-len_prices:]].values.reshape((len_prices, 1))\n",
        "        # Para cada característica\n",
        "        for j in range(n_features):\n",
        "            # Se obtiene los 48 rezagos y se voltea el arreglo para tener el más antiguo primero\n",
        "            # Aquí se aplica el supuesto de que el dataframe tiene 5 columnas de 5\n",
        "            features[i, :, j] = np.flip(df.iloc[i, 5+48*j:5+len_features + 48*j].values)\n",
        "    return prices, features"
      ],
      "metadata": {
        "id": "pZ-N7rf_9HJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The Input data contains 10 time series of 48 trading hours representing complementary features based on sentiment analysis from news extracted from twitter or forums like Bitcointalk on Bitcoin, and 5 time series based on the variation of Bitcoin price during the past 1, 6, 12, 24 and 48 hours normalised by volatility during the period. Input data, for training and testing, will be given by a .csv file, whose first line contains the header. Then each line corresponds to a sample, each column to a feature. The features are the following:\n",
        "\n",
        ">- ***ID***: Id of the sample which is linked to the ID of the output file;\n",
        "- ***I_1_lag(k)*** to ***I_10_lag(k)***: Values of Indicators *I_1* to *I_10* for each k lag ($k\\in[\\![0;47]\\!]$) representing the normalized value of Indicators *I_1* to *I_10* each hour of the past 48 trading hours;\n",
        "- ***X_1*** to ***X_5***: Values of 5 normalised indicators representing price variation of Bitcoin on the last 1, 6, 12, 24 and 48 hours.\n",
        "\n",
        "> There will be 14 000 samples for the train set and 5 000 for the test set. For a given sample, the time series (for the 10 sentiment indicators) are given over the same 48 trading hours.\n",
        "\n",
        ">The training outputs are given in a .csv file. Each line corresponds to a sample:\n",
        "\n",
        ">- ***ID***: Id of the sample;\n",
        "- ***Target_-1***: classification of the return of Bitcoin in the next hour. -1 signifies a down move of less than -0.2%;\n",
        "- ***Target_0***: classification of the return of Bitcoin in the next hour. 0 signifies a move between -0.2% and 0.2%;\n",
        "- ***Target_1***: classification of the return of Bitcoin in the next hour. 1 signifies a up move of more than 0.2%.\n",
        "\n"
      ],
      "metadata": {
        "id": "XT_-69IHrvk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_raw = pd.read_csv('/content/drive/MyDrive/Cruso-ApsFinancieras/semana7/input_training_IrTAw7w.csv').set_index('ID')\n",
        "X_raw"
      ],
      "metadata": {
        "id": "x20PPm-uf29p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_raw.loc[:,'I1_lag0':'I1_lag47']"
      ],
      "metadata": {
        "id": "dIjFLbzS_dJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_raw = pd.read_csv('/content/drive/MyDrive/Cruso-ApsFinancieras/semana7/output_training_F2dZW38.csv').set_index('ID')\n",
        "y_raw"
      ],
      "metadata": {
        "id": "29-SdvrDk-lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## División: Entrenamiento, Validación y Prueba"
      ],
      "metadata": {
        "id": "4fqHIttJ8RTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Division para entrenamiento de red LSTM\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, train_size = .8, random_state = 10, shuffle = False)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size = .75, random_state = 10, shuffle = False)\n",
        "\n",
        "print('     Train shape', X_train.shape)\n",
        "print('Validation shape', X_val.shape)\n",
        "print('      Test shape', X_test.shape)"
      ],
      "metadata": {
        "id": "1X0rE_Qj1Ys0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformaciones"
      ],
      "metadata": {
        "id": "LV5EgGdD8WAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Longitud de la serie de tiempo de variaciones de los precios del Bitcoin X_i\n",
        "len_prices = 5\n",
        "\n",
        "# Cantidad de temas vistos\n",
        "n_features = 10\n",
        "# Cantidad de tiempos que vemos hacia atras en las variables de sentimiento\n",
        "len_features = 48\n",
        "\n",
        "train_prices, train_features = transform_dataframe(X_train, len_prices, n_features, len_features)\n",
        "val_prices, val_features     = transform_dataframe(X_val,   len_prices, n_features, len_features)\n",
        "test_prices, test_features   = transform_dataframe(X_test,  len_prices, n_features, len_features)"
      ],
      "metadata": {
        "id": "E9kHbyBf-hUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_prices[0]"
      ],
      "metadata": {
        "id": "IVAOnEUuSvuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_prices.shape"
      ],
      "metadata": {
        "id": "K2QzZtVH3FZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features[0][:, 0]"
      ],
      "metadata": {
        "id": "upcIoCRrTx9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_raw.loc[:,'I1_lag0':'I1_lag47']"
      ],
      "metadata": {
        "id": "zG_vcD88TGvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.shape"
      ],
      "metadata": {
        "id": "11OHHU132d-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('        Labels: (samples, sequence length, features)')\n",
        "print('  Train prices:', train_prices.shape)\n",
        "print('Train features:', train_features.shape)"
      ],
      "metadata": {
        "id": "D9vHnzXOGlJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algoritmos-Modelos"
      ],
      "metadata": {
        "id": "Z8wnN8eN8fbZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regresión logística"
      ],
      "metadata": {
        "id": "NfcAiYGc994C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El punto de referencia de los propietarios de los datos es una regresión logística tomando como características X1, $\\dots$, X5."
      ],
      "metadata": {
        "id": "0B2PDjT2-_n-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "XxRMOiQR2d3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "train_prices"
      ],
      "metadata": {
        "id": "hi_GmUvP3InB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(X_raw, y_raw, train_size = .8, random_state = 10, shuffle = False)"
      ],
      "metadata": {
        "id": "-gaJ6tl43i7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_0 = X_train_0[['X1', 'X2', 'X3', 'X4', 'X5']]\n",
        "X_train_0"
      ],
      "metadata": {
        "id": "ZF4hOjid3tza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_0 = X_test_0[['X1', 'X2', 'X3', 'X4', 'X5']]\n",
        "X_test_0"
      ],
      "metadata": {
        "id": "dJZBRMLB4ueT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_0"
      ],
      "metadata": {
        "id": "o_7JNo-aII09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_0 = y_train_0.idxmax(axis=1)\n",
        "y_train_0"
      ],
      "metadata": {
        "id": "0AOe0xet4bSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_0 = y_test_0.idxmax(axis=1)\n",
        "y_test_0"
      ],
      "metadata": {
        "id": "baOggV1r42-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = LogisticRegression(multi_class='multinomial', random_state=1)"
      ],
      "metadata": {
        "id": "RCCmUlbR1yPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0"
      ],
      "metadata": {
        "id": "AX6I3YOnOA1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.fit(X_train_0, y_train_0 )"
      ],
      "metadata": {
        "id": "AHrjeE4N1yNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_0 = model_0.predict(X_test_0)"
      ],
      "metadata": {
        "id": "O4q32k1J1yLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(y_pred_0 == y_test_0).sum() / len(y_pred_0)"
      ],
      "metadata": {
        "id": "dpulvfSw1yIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_0, y_pred_0))"
      ],
      "metadata": {
        "id": "tlJD5hYd1yGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "1pOr7LWI1yDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_test_0, y_pred_0)"
      ],
      "metadata": {
        "id": "ZCFn_Ufu1x7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss"
      ],
      "metadata": {
        "id": "vFAcWW8vJxse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Otra salida útil del modelo\n",
        "model_0.predict_proba(X_test_0)"
      ],
      "metadata": {
        "id": "IyKzDrQ5Kh4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_0"
      ],
      "metadata": {
        "id": "Q3iszsDTPFTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_loss(y_test_0, model_0.predict_proba(X_test_0))"
      ],
      "metadata": {
        "id": "LaZDE91CJ1Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redes Neuronales"
      ],
      "metadata": {
        "id": "HtIZY1aI8il-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Callbacks"
      ],
      "metadata": {
        "id": "uOph68NN8xcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Los guarda en GoogleDrive, si no se quiere hacer la conexión, entonces cambiar la ruta o quitar el callback\n",
        "# checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "#     filepath = 'checkpoints', \n",
        "#     save_best_only = True\n",
        "# )\n",
        "\n",
        "earlystop_cb = keras.callbacks.EarlyStopping(\n",
        "    patience = 25, \n",
        "    restore_best_weights = True\n",
        ")"
      ],
      "metadata": {
        "id": "y43mqM-dMTXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Primera Aquitectura (Solo utilizando Caracteristicas de Bitcoin)"
      ],
      "metadata": {
        "id": "iSTqABok8o6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aquitectura"
      ],
      "metadata": {
        "id": "qVpiKL0s84gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definicion de las capas\n",
        "price_input = layers.Input(shape = (len_prices, 1), name = 'price_input')\n",
        "price_normalization = layers.Normalization(name = 'price_normalization', axis = 1)\n",
        "price_lstm = layers.LSTM(32, name = 'price', \n",
        "                        # kernel_regularizer=keras.regularizers.l1_l2(l1 = 1e-1, l2 = 1e-1),\n",
        "                         return_sequences=True, \n",
        "                         )\n",
        "\n",
        "price_lstm2 = layers.LSTM(16, name='price2')\n",
        "\n",
        "# Como se conectan las capas definidas arriba\n",
        "price_normalized = price_normalization(price_input)\n",
        "price_output = price_lstm(price_normalized)\n",
        "price_output2 = price_lstm2(price_output)\n",
        "\n",
        "# Como se conecta lo posterior\n",
        "prediction_layer = keras.models.Sequential(\n",
        "    [\n",
        "     layers.Dense(32, activation = 'relu'), \n",
        "     layers.Dense(32, activation = 'relu'), \n",
        "     layers.Dense(32, activation = 'relu'), \n",
        "     layers.Dense(3, activation = 'softmax')\n",
        "    ], \n",
        "    name = 'prediction'\n",
        ")\n",
        "prediction_output = prediction_layer(price_output2) \n"
      ],
      "metadata": {
        "id": "RoNA7N2J2kZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Modelo"
      ],
      "metadata": {
        "id": "uSxbBiV09FId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciación del objeto modelo\n",
        "model = keras.Model(price_input, prediction_output)\n",
        "\n",
        "model.compile(\n",
        "    loss = 'categorical_crossentropy'\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "sZwINhfBLOrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Visualización"
      ],
      "metadata": {
        "id": "TZOU1FjI9G4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización del modelo\n",
        "keras.utils.plot_model( \n",
        "    model,\n",
        "    to_file=\"model.png\",\n",
        "    show_shapes=True,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"TD\",\n",
        "    dpi=100,\n",
        ")"
      ],
      "metadata": {
        "id": "sJ-Ge0skLY0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento"
      ],
      "metadata": {
        "id": "Op_r0jcC9J24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_prices, y_train,\n",
        "    batch_size = 128,\n",
        "    epochs = 1000,  # Valor real de 1000 \n",
        "    callbacks = [earlystop_cb], \n",
        "    validation_data = [val_prices, y_val]\n",
        ").history"
      ],
      "metadata": {
        "id": "jkOOKs_pLosa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Visualización"
      ],
      "metadata": {
        "id": "1MMSErL09Lde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = list(range(len(history['loss'])))\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x = x, y = history['loss'])) \\\n",
        "   .add_trace(go.Scatter(x = x, y = history['val_loss']))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "U0VeDdOhTAPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Métricas"
      ],
      "metadata": {
        "id": "pZN1xAdq9Plc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, [train_prices, y_train], [val_prices, y_val], [test_prices, y_test])"
      ],
      "metadata": {
        "id": "nSHaBMRB3BFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(test_prices)"
      ],
      "metadata": {
        "id": "WelnycacezHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob"
      ],
      "metadata": {
        "id": "gAhkRyVOe_mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred_prob.argmax(axis=1)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "M8j0dK2_fIqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_f = y_test.idxmax(axis=1).map({'Target -1': 0, 'Target 0': 1, 'Target 1': 2})"
      ],
      "metadata": {
        "id": "PtkfoJNkhvBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_test_f, y_pred)"
      ],
      "metadata": {
        "id": "sO8yw1p6e56-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConfusionMatrixDisplay.from_predictions(y_test_0, y_pred_0)"
      ],
      "metadata": {
        "id": "m9SlkWqOiuxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_f, y_pred))"
      ],
      "metadata": {
        "id": "N-VlC-mhi4Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Segunda Arquitectura"
      ],
      "metadata": {
        "id": "EinK3G6r9kAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Arquitectura"
      ],
      "metadata": {
        "id": "tSKt3k3d9mle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fusion_dim = 8\n",
        "\n",
        "price_input = layers.Input(shape = (len_prices,), name = 'price_input')\n",
        "\n",
        "price_layer = keras.models.Sequential(\n",
        "    [\n",
        "     layers.Normalization(name = 'price_normalization'), \n",
        "     layers.Dense(8, activation = 'tanh'), \n",
        "     layers.Dense(8, activation = 'relu'),\n",
        "     layers.Dense(8, activation = 'tanh'), \n",
        "     layers.Dense(fusion_dim, activation = 'relu'),\n",
        "    ], \n",
        "    name = 'price'\n",
        ")\n",
        "\n",
        "price_output = price_layer(price_input)\n",
        "\n",
        "sentiment_input = layers.Input(shape = (len_features, n_features), name = 'sentiment_input')\n",
        "sentiment_normalization = layers.Normalization(name = 'sentiment_normalization', axis = 1)\n",
        "sentiment_lstm = layers.LSTM(fusion_dim, name = 'sentiment')\n",
        "\n",
        "sentiment_normalized = sentiment_normalization(sentiment_input)\n",
        "sentiment_output = sentiment_lstm(sentiment_normalized)\n",
        "\n",
        "fusion = layers.Multiply(name = 'hadamard_product')([sentiment_output, price_output])\n",
        "\n",
        "prediction_layer = keras.models.Sequential(\n",
        "    [\n",
        "     layers.Dense(8, activation = 'tanh'), \n",
        "     layers.Dense(8, activation = 'relu'), \n",
        "     layers.Dense(8, activation = 'sigmoid'), \n",
        "     layers.Dense(3, activation = 'softmax')\n",
        "    ], \n",
        "    name = 'prediction'\n",
        ")\n",
        "prediction_output = prediction_layer(fusion)"
      ],
      "metadata": {
        "id": "4s3tIf0m2p2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Modelo"
      ],
      "metadata": {
        "id": "HhmCFsf89phq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = keras.Model([price_input, sentiment_input], prediction_output)\n",
        "\n",
        "model_2.compile(\n",
        "    loss = 'categorical_crossentropy'\n",
        ")\n",
        "\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "DmQXsGd63SfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Visualización"
      ],
      "metadata": {
        "id": "ct6SNKKd9rS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model( \n",
        "    model_2,\n",
        "    to_file=\"model.png\",\n",
        "    show_shapes=True,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"TD\",\n",
        "    dpi=90,\n",
        ")"
      ],
      "metadata": {
        "id": "-Kr3cOHZ3WVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento"
      ],
      "metadata": {
        "id": "BpHIwaTI9tVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_2.fit(\n",
        "    [train_prices, train_features], y_train, \n",
        "    epochs = 30, # Original, 1000 épocas\n",
        "    callbacks = [earlystop_cb], \n",
        "    validation_data = [[val_prices, val_features], y_val]\n",
        ").history"
      ],
      "metadata": {
        "id": "2uSf0H5r3Yc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Visualización"
      ],
      "metadata": {
        "id": "DarEX0pr9wQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = list(range(len(history['loss'])))\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x = x, y = history['loss'])) \\\n",
        "   .add_trace(go.Scatter(x = x, y = history['val_loss'])) \\\n",
        "   .update_layout(hovermode = 'x')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "0iC6uX4J3s24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Métricas"
      ],
      "metadata": {
        "id": "5DJZSDuM9zbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model_2, [[train_prices, train_features], y_train], [[val_prices, val_features], y_val], [[test_prices, test_features], y_test])"
      ],
      "metadata": {
        "id": "FGkJ3j0k3vqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Guardando el mejor modelo"
      ],
      "metadata": {
        "id": "Bkzl6Rl3MpjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.save('best_model.h5')"
      ],
      "metadata": {
        "id": "mt-RDfH5Mr-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar el modelo guardado"
      ],
      "metadata": {
        "id": "NPGWlldUNYWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = keras.models.load_model('best_model.h5')\n",
        "best_model.summary()"
      ],
      "metadata": {
        "id": "_yc7PIa7NahC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(best_model, [[train_prices, train_features], y_train], [[val_prices, val_features], y_val], [[test_prices, test_features], y_test])"
      ],
      "metadata": {
        "id": "FcNI6n5gNjPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumen\n",
        "\n",
        "Respecto a la segunda arquitectura:\n",
        "\n",
        "1. Fue la que tuvo mejores resultados con entropía cruzada de $0.9843$, $1.0256$ y $1.0329$ para los conjuntos de entrenamiento, validación y prueba, respectivamente.\n",
        "2. Tardó menos épocas en entrenar\n",
        "\n"
      ],
      "metadata": {
        "id": "WIJI7v2IBK7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicios"
      ],
      "metadata": {
        "id": "8mHRbHGAKjxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Crear un nuevo modelo ya sea haciendo modificaciones a alguna de las arquitecturas presentes, o comenzando desde cero. Escriba sus observaciones comparando el resultado con el mejor la Segunda Arquitectura. Como sugerencia, puede probar cambiando los datos de entrada, las capas de las redes secuenciales, la fusión de los datos, agregando regularización o dropout, callbacks, etc. \n",
        "2. ¿Cómo haría la predicción para nuevos valores?\n",
        "\n",
        "3. Cree las matrices de confusión para la última red neuronal, así como el classification report.\n"
      ],
      "metadata": {
        "id": "5Y73It2dKmdF"
      }
    }
  ]
}